# -*- coding: utf-8 -*-
"""Thyroid disease classification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZViq8fiKPkq9a4MDcfX9lItUxQAjRGRN

# Importing libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/thyroidDF.csv')

df.head()

df.info()

df.describe()

"""# Data Preprocessing

Categorical variables
"""

categorical_variables = []
for i in df.columns:
  if df[i].dtypes == 'O':
    categorical_variables.append(i)

categorical_variables

"""Removing unwanted columns"""

df.drop(columns = ['patient_id','referral_source'], inplace = True)

df.head()

numerical_variables = []
for cols in df.columns:
  if df[cols].dtypes != 'O':
    numerical_variables.append(cols)

numerical_variables

# descrete variables
descrete_variables = []
for cols in numerical_variables:
  if len(df[cols].unique()) <= 100:
    descrete_variables.append(cols)

descrete_variables

#continous variables
continous_variables = []
for cols in numerical_variables:
  if cols not in descrete_variables:
    continous_variables.append(cols)

continous_variables

"""Checking for the outliers using boxplot"""

for cols in continous_variables:
  sns.boxplot(df[cols])
  plt.title(cols)
  plt.show()

"""Missing values"""

df.isnull().sum()

columns_with_missing = []
for cols in df.columns:
  if df[cols].isnull().sum() > 1:
    columns_with_missing.append(cols)

columns_with_missing

df[columns_with_missing].info()

sex_mapping = {'M':1, 'F':0}
df['sex'] = df['sex'].map(sex_mapping)

df.head()

#filling the 'sex' column with the most frequent data
most_frequent_sex = df['sex'].mode().values[0]
df['sex'].fillna(most_frequent_sex, inplace = True)

df['sex'].isnull().sum()

"""Filling the remaining missing values with KNNImputer as they are floating values."""

from sklearn.impute import KNNImputer
knn_imputer = KNNImputer(n_neighbors=5)

columns_with_missing = []
for cols in df.columns:
  if df[cols].isnull().sum() > 1:
    columns_with_missing.append(cols)
columns_with_missing

for cols in columns_with_missing:
  df[cols] = knn_imputer.fit_transform(df[[cols]])

"""Checking the distribution of the numerical continous data."""

for cols in continous_variables:
  sns.histplot(df[cols], bins = 100)
  plt.title(cols)
  plt.show()

"""# Feature Engineering"""

for cols in continous_variables:
  print('mean of:',cols, np.mean(df[cols]))
  print('median of:',cols, np.median(df[cols]))

"""According to the statistics TSH is positively skewed."""

# log transformation of TSH column
df['TSH'] = np.log(df['TSH'])

sns.histplot(df['TSH'])

df.head()

columns_with_two_cat = []
for cols in df.columns:
  if len(df[cols].unique()) == 2:
    columns_with_two_cat.append(cols)

columns_with_two_cat

"""Feature encoding"""

# Encoding the columns with true and false
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()

for cols in columns_with_two_cat:
  df[cols] = encoder.fit_transform(df[cols])

df.head()

sns.heatmap(df.corr())

df['target'].unique()

target_map = {
    '-':1, 'S':2, 'F':3, 'AK':4, 'R':5, 'I':6, 'M':7, 'N':8, 'G':9, 'K':10, 'A':11, 'KJ':12, 'L':13,
       'MK':14, 'Q':15, 'J':16, 'C|I':17, 'O':18, 'LJ':19, 'H|K':20, 'D':21, 'GK':22, 'MI':23, 'P':24,
       'FK':25, 'B':26, 'GI':27, 'C':28, 'GKJ':29, 'OI':30, 'D|R':31, 'E':32
}

df['target'] = df['target'].map(target_map)

df['target'].unique()

"""# Cross validation"""

x = df.drop(columns = 'target')
y = df['target']

from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier()

from sklearn.ensemble import GradientBoostingClassifier
gb_classifier = GradientBoostingClassifier()

from sklearn.model_selection import cross_val_score
cv_score = cross_val_score(classifier,x,y,cv=5,scoring = 'accuracy')
print('mean accuracy:',np.mean(cv_score))
print('standard deviation:',np.std(cv_score))

cv_score_gb = cross_val_score(gb_classifier,x,y,cv=5,scoring = 'accuracy')
print('mean accuracy gradient boosting:',np.mean(cv_score_gb))
print('standard deviation gradient boosting:',np.std(cv_score_gb))

"""# Model Training"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2)

classifier.fit(x_train,y_train)

"""# Model evaluation"""

y_pred = classifier.predict(x_test)

from sklearn.metrics import accuracy_score, classification_report
print('accuracy:',accuracy_score(y_test,y_pred))
print('classification report:',classification_report(y_test,y_pred))

"""Calculating mathrews correlation coefficeint

# Feature importance
"""

feature_importances = classifier.feature_importances_

feature_importance_df = pd.DataFrame({'Features':x_train.columns,'Importance':feature_importances})
feature_importance_df = feature_importance_df.sort_values(by = 'Importance', ascending = False)
feature_importance_df.head(7)

